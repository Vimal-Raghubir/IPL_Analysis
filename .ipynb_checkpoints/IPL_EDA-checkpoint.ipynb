{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b42b04",
   "metadata": {},
   "source": [
    "# IPL Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0406fe17",
   "metadata": {},
   "source": [
    "## This notebook serves to explore the data of all IPL player statistics between 2016 and 2022. There will be EDA conducted on both the bowling and the batting statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b19557",
   "metadata": {},
   "source": [
    "### 1. Import the data into the notebook. \n",
    "First I will define a function to load in data given a file path and a filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "edf7dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "def load_data(file_path , filename):\n",
    "    \n",
    "    csv_path = os.path.join(file_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ccf87266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv_data(file_path, filename, df):\n",
    "    csv_path = os.path.join(file_path, filename)\n",
    "    df.to_csv(csv_path)\n",
    "    \n",
    "    if os.path.exists(csv_path) and os.path.getsize(csv_path) > 0:\n",
    "        print(filename + \" was written to successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b28675",
   "metadata": {},
   "source": [
    "#### 1a. Load in batting data\n",
    "We will then call the function to load in all batting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a370be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_file_path = \"Data/Batting_Stats\"\n",
    "\n",
    "\n",
    "# All batting dataframes\n",
    "df_batting_2016 = load_data(batting_file_path, \"BATTING_STATS-IPL_2016.csv\")\n",
    "df_batting_2017 = load_data(batting_file_path, \"BATTING_STATS-IPL_2017.csv\")\n",
    "df_batting_2018 = load_data(batting_file_path, \"BATTING_STATS-IPL_2018.csv\")\n",
    "df_batting_2019 = load_data(batting_file_path, \"BATTING_STATS-IPL_2019.csv\")\n",
    "df_batting_2020 = load_data(batting_file_path, \"BATTING_STATS-IPL_2020.csv\")\n",
    "df_batting_2021 = load_data(batting_file_path, \"BATTING_STATS-IPL_2021.csv\")\n",
    "df_batting_2022 = load_data(batting_file_path, \"BATTING_STATS-IPL_2022.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d72164",
   "metadata": {},
   "source": [
    "#### 1b. Load in bowling data\n",
    "We will then call the function to load in all bowling data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7968a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowling_file_path = \"Data/Bowling_Stats\"\n",
    "\n",
    "# All bowling dataframes\n",
    "df_bowling_2016 = load_data(bowling_file_path, \"BOWLING_STATS-IPL_2016.csv\")\n",
    "df_bowling_2017 = load_data(bowling_file_path, \"BOWLING_STATS-IPL_2017.csv\")\n",
    "df_bowling_2018 = load_data(bowling_file_path, \"BOWLING_STATS-IPL_2018.csv\")\n",
    "df_bowling_2019 = load_data(bowling_file_path, \"BOWLING_STATS-IPL_2019.csv\")\n",
    "df_bowling_2020 = load_data(bowling_file_path, \"BOWLING_STATS-IPL_2020.csv\")\n",
    "df_bowling_2021 = load_data(bowling_file_path, \"BOWLING_STATS-IPL_2021.csv\")\n",
    "df_bowling_2022 = load_data(bowling_file_path, \"BOWLING_STATS-IPL_2022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17a838",
   "metadata": {},
   "source": [
    "### 2. Take a first look at the dataframes\n",
    "We will use some basic dataframe commands to inspect the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f536461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>Player</th>\n",
       "      <th>Mat</th>\n",
       "      <th>Inns</th>\n",
       "      <th>NO</th>\n",
       "      <th>Runs</th>\n",
       "      <th>HS</th>\n",
       "      <th>Avg</th>\n",
       "      <th>BF</th>\n",
       "      <th>SR</th>\n",
       "      <th>100</th>\n",
       "      <th>50</th>\n",
       "      <th>4s</th>\n",
       "      <th>6s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jos Buttler</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>863</td>\n",
       "      <td>116</td>\n",
       "      <td>57.53</td>\n",
       "      <td>579</td>\n",
       "      <td>149.05</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>K L Rahul</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>616</td>\n",
       "      <td>103*</td>\n",
       "      <td>51.33</td>\n",
       "      <td>455</td>\n",
       "      <td>135.38</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quinton De Kock</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>508</td>\n",
       "      <td>140*</td>\n",
       "      <td>36.29</td>\n",
       "      <td>341</td>\n",
       "      <td>148.97</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hardik Pandya</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>487</td>\n",
       "      <td>87*</td>\n",
       "      <td>44.27</td>\n",
       "      <td>371</td>\n",
       "      <td>131.26</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>483</td>\n",
       "      <td>96</td>\n",
       "      <td>34.5</td>\n",
       "      <td>365</td>\n",
       "      <td>132.32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POS           Player  Mat  Inns  NO  Runs    HS    Avg   BF      SR  100  \\\n",
       "0    1      Jos Buttler   17    17   2   863   116  57.53  579  149.05    4   \n",
       "1    2        K L Rahul   15    15   3   616  103*  51.33  455  135.38    2   \n",
       "2    3  Quinton De Kock   15    15   1   508  140*  36.29  341  148.97    1   \n",
       "3    4    Hardik Pandya   15    15   4   487   87*  44.27  371  131.26    0   \n",
       "4    5     Shubman Gill   16    16   2   483    96   34.5  365  132.32    0   \n",
       "\n",
       "   50  4s  6s  \n",
       "0   4  83  45  \n",
       "1   4  45  30  \n",
       "2   3  47  23  \n",
       "3   4  49  12  \n",
       "4   4  51  11  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_batting_2022.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b1da0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>Player</th>\n",
       "      <th>Mat</th>\n",
       "      <th>Inns</th>\n",
       "      <th>Ov</th>\n",
       "      <th>Runs</th>\n",
       "      <th>Wkts</th>\n",
       "      <th>BBI</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Econ</th>\n",
       "      <th>SR</th>\n",
       "      <th>4w</th>\n",
       "      <th>5w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yuzvendra Chahal</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>68.0</td>\n",
       "      <td>527</td>\n",
       "      <td>27</td>\n",
       "      <td>40/5</td>\n",
       "      <td>19.51</td>\n",
       "      <td>7.75</td>\n",
       "      <td>15.11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Wanindu Hasaranga</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>57.0</td>\n",
       "      <td>430</td>\n",
       "      <td>26</td>\n",
       "      <td>18/5</td>\n",
       "      <td>16.53</td>\n",
       "      <td>7.54</td>\n",
       "      <td>13.15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>48.0</td>\n",
       "      <td>406</td>\n",
       "      <td>23</td>\n",
       "      <td>33/4</td>\n",
       "      <td>17.65</td>\n",
       "      <td>8.45</td>\n",
       "      <td>12.52</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Umran Malik</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>49.1</td>\n",
       "      <td>444</td>\n",
       "      <td>22</td>\n",
       "      <td>25/5</td>\n",
       "      <td>20.18</td>\n",
       "      <td>9.03</td>\n",
       "      <td>13.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Kuldeep Yadav</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>49.4</td>\n",
       "      <td>419</td>\n",
       "      <td>21</td>\n",
       "      <td>14/4</td>\n",
       "      <td>19.95</td>\n",
       "      <td>8.43</td>\n",
       "      <td>14.19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POS             Player  Mat  Inns    Ov  Runs  Wkts   BBI    Avg  Econ  \\\n",
       "0    1   Yuzvendra Chahal   17    17  68.0   527    27  40/5  19.51  7.75   \n",
       "1    2  Wanindu Hasaranga   16    16  57.0   430    26  18/5  16.53  7.54   \n",
       "2    3      Kagiso Rabada   13    13  48.0   406    23  33/4  17.65  8.45   \n",
       "3    4        Umran Malik   14    14  49.1   444    22  25/5  20.18  9.03   \n",
       "4    5      Kuldeep Yadav   14    14  49.4   419    21  14/4  19.95  8.43   \n",
       "\n",
       "      SR  4w  5w  \n",
       "0  15.11   1   1  \n",
       "1  13.15   1   1  \n",
       "2  12.52   2   0  \n",
       "3  13.40   1   1  \n",
       "4  14.19   2   0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bowling_2022.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14bafa5",
   "metadata": {},
   "source": [
    "### 2a. Info function analysis\n",
    "Info function will give us details on whether any fields contain null values and after running the function on all dataframes, there doesn't seem to be any null values. This is very good.\n",
    "\n",
    "We can see however that the highest score, average and BBI columns are all strings. This is a problem for the average column since it needs to be a float but BBI will always contain a slash and high score can contain an * to indicate not out. We will omit both BBI and High Score since it is not needed for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c66ed09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 133 entries, 0 to 132\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   POS     133 non-null    int64  \n",
      " 1   Player  133 non-null    object \n",
      " 2   Mat     133 non-null    int64  \n",
      " 3   Inns    133 non-null    int64  \n",
      " 4   NO      133 non-null    int64  \n",
      " 5   Runs    133 non-null    int64  \n",
      " 6   HS      133 non-null    object \n",
      " 7   Avg     133 non-null    float64\n",
      " 8   BF      133 non-null    int64  \n",
      " 9   SR      133 non-null    float64\n",
      " 10  100     133 non-null    int64  \n",
      " 11  50      133 non-null    int64  \n",
      " 12  4s      133 non-null    int64  \n",
      " 13  6s      133 non-null    int64  \n",
      "dtypes: float64(2), int64(10), object(2)\n",
      "memory usage: 14.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_batting_2020.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ce76c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103 entries, 0 to 102\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   POS     103 non-null    int64  \n",
      " 1   Player  103 non-null    object \n",
      " 2   Mat     103 non-null    int64  \n",
      " 3   Inns    103 non-null    int64  \n",
      " 4   Ov      103 non-null    float64\n",
      " 5   Runs    103 non-null    int64  \n",
      " 6   Wkts    103 non-null    int64  \n",
      " 7   BBI     103 non-null    object \n",
      " 8   Avg     103 non-null    float64\n",
      " 9   Econ    103 non-null    float64\n",
      " 10  SR      103 non-null    float64\n",
      " 11  4w      103 non-null    int64  \n",
      " 12  5w      103 non-null    int64  \n",
      "dtypes: float64(4), int64(7), object(2)\n",
      "memory usage: 10.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bowling_2022.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571bda6",
   "metadata": {},
   "source": [
    "### 3. Fix issues in the concatenated datasets\n",
    "We need to address the BBI, High Score, and Average column for both batting and bowling data. Will create utility functions for each discipline to handle the cleaning in a functional way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62cfec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanBattingData(df_batting):\n",
    "    # Handles cleaning the Average column\n",
    "    df_batting['Avg'] = df_batting['Avg'].astype(str)\n",
    "    df_batting['Avg'] = df_batting['Avg'].str.replace(\"-\", \"0\")\n",
    "    df_batting['Avg'] = df_batting['Avg'].str.strip(\"\")\n",
    "    df_batting['Avg'] = df_batting['Avg'].astype('float64')\n",
    "\n",
    "    # Removing unneeded * from High Score column\n",
    "    df_batting['HS'] = df_batting['HS'].str.replace(\"*\", \"\")\n",
    "    \n",
    "    # Dropping unneeded POS column\n",
    "    df_batting.drop(['POS'], axis=1, inplace=True)\n",
    "    \n",
    "    return df_batting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6585f1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_batting_data_2016.csv was written to successfully!\n",
      "cleaned_batting_data_2017.csv was written to successfully!\n",
      "cleaned_batting_data_2018.csv was written to successfully!\n",
      "cleaned_batting_data_2019.csv was written to successfully!\n",
      "cleaned_batting_data_2020.csv was written to successfully!\n",
      "cleaned_batting_data_2021.csv was written to successfully!\n",
      "cleaned_batting_data_2022.csv was written to successfully!\n"
     ]
    }
   ],
   "source": [
    "df_clean_batting_2016 = cleanBattingData(df_batting_2016)\n",
    "df_clean_batting_2017 = cleanBattingData(df_batting_2017)\n",
    "df_clean_batting_2018 = cleanBattingData(df_batting_2018)\n",
    "df_clean_batting_2019 = cleanBattingData(df_batting_2019)\n",
    "df_clean_batting_2020 = cleanBattingData(df_batting_2020)\n",
    "df_clean_batting_2021 = cleanBattingData(df_batting_2021)\n",
    "df_clean_batting_2022 = cleanBattingData(df_batting_2022)\n",
    "\n",
    "\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Batting\", \"cleaned_batting_data_2016.csv\", df_clean_batting_2016)\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Batting\", \"cleaned_batting_data_2017.csv\", df_clean_batting_2017)\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Batting\", \"cleaned_batting_data_2018.csv\", df_clean_batting_2018)\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Batting\", \"cleaned_batting_data_2019.csv\", df_clean_batting_2019)\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Batting\", \"cleaned_batting_data_2020.csv\", df_clean_batting_2020)\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Batting\", \"cleaned_batting_data_2021.csv\", df_clean_batting_2021)\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Batting\", \"cleaned_batting_data_2022.csv\", df_clean_batting_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63e9b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanBowlingData(df_bowling):\n",
    "    # Dropping unneeded POS column\n",
    "    df_bowling.drop(['POS'], axis=1, inplace=True)\n",
    "\n",
    "    # Dropping unneeded BBI column\n",
    "    df_bowling.drop(['BBI'], axis=1, inplace=True)\n",
    "    \n",
    "    return df_bowling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c42ff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_bowling_data_2016.csv was written to successfully!\n",
      "cleaned_bowling_data_2017.csv was written to successfully!\n",
      "cleaned_bowling_data_2018.csv was written to successfully!\n",
      "cleaned_bowling_data_2019.csv was written to successfully!\n",
      "cleaned_bowling_data_2020.csv was written to successfully!\n",
      "cleaned_bowling_data_2021.csv was written to successfully!\n",
      "cleaned_bowling_data_2022.csv was written to successfully!\n"
     ]
    }
   ],
   "source": [
    "df_clean_bowling_2016 = cleanBowlingData(df_bowling_2016)\n",
    "df_clean_bowling_2017 = cleanBowlingData(df_bowling_2017)\n",
    "df_clean_bowling_2018 = cleanBowlingData(df_bowling_2018)\n",
    "df_clean_bowling_2019 = cleanBowlingData(df_bowling_2019)\n",
    "df_clean_bowling_2020 = cleanBowlingData(df_bowling_2020)\n",
    "df_clean_bowling_2021 = cleanBowlingData(df_bowling_2021)\n",
    "df_clean_bowling_2022 = cleanBowlingData(df_bowling_2022)\n",
    "\n",
    "\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Bowling\", \"cleaned_bowling_data_2016.csv\", df_clean_bowling_2016)\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Bowling\", \"cleaned_bowling_data_2017.csv\", df_clean_bowling_2017)\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Bowling\", \"cleaned_bowling_data_2018.csv\", df_clean_bowling_2018)\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Bowling\", \"cleaned_bowling_data_2019.csv\", df_clean_bowling_2019)\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Bowling\", \"cleaned_bowling_data_2020.csv\", df_clean_bowling_2020)\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Bowling\", \"cleaned_bowling_data_2021.csv\", df_clean_bowling_2021)\n",
    "write_csv_data(\"Outputs\\Cleaned_Datasets\\Bowling\", \"cleaned_bowling_data_2022.csv\", df_clean_bowling_2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e5a8dc",
   "metadata": {},
   "source": [
    "### 3. Combine dataframes for all years into a single dataframe\n",
    "We can combine the batting data and bowling data to represent all of the players' statistics regardless of the year they took place. This will give us a large enough dataset that we can potentially use a regression model to forecast runs for batsmen based on features and wickets for bowlers based on features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2673e755",
   "metadata": {},
   "source": [
    "#### 3a. Combining and formatting batting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b2fa6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineDataFramesWithSeasonCount(df_list):\n",
    "    # This is used to concatenate the dataframes and count the number of seasons each player played by counting the duplicates\n",
    "    df_season_count = pd.concat(df_list)['Player'].value_counts().reset_index()\n",
    "    # We will rename the columns for the this dataframe to easily merge into the total dataframe\n",
    "    df_season_count = df_season_count.rename(columns={\"Player\": \"Seasons\", \"index\": \"Player\"})\n",
    "    \n",
    "    # This concatenation will produce the actual total dataframe with unique entries for each player because of groupby\n",
    "    df_all = pd.concat(df_list).groupby(['Player']).sum().reset_index()\n",
    "    # We merge the season count into the total dataframe to add the Season column\n",
    "    df_all_with_season_count = df_all.merge(df_season_count, on='Player', how='left')\n",
    "\n",
    "    return df_all_with_season_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8156cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatBattingCombined(df_batting_combined):\n",
    "    # Will divide average and Strike Rate by number of seasons to get the average of these metrics across all seasons\n",
    "    df_batting_combined['Avg'] = round(df_batting_combined['Avg'] / df_batting_combined['Seasons'],2)\n",
    "    df_batting_combined['SR'] = round(df_batting_combined['SR'] / df_batting_combined['Seasons'],2)\n",
    "    \n",
    "    return df_batting_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25da1cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_and_formatted_batting.csv was written to successfully!\n"
     ]
    }
   ],
   "source": [
    "batting_list = [df_clean_batting_2016, df_clean_batting_2017, df_clean_batting_2018, df_clean_batting_2019, df_clean_batting_2020\n",
    "                , df_clean_batting_2021, df_clean_batting_2022]\n",
    "\n",
    "df_batting_combined = combineDataFramesWithSeasonCount(batting_list)\n",
    "df_batting_combined_formatted = formatBattingCombined(df_batting_combined)\n",
    "write_csv_data(\"Outputs\\Combined\", \"combined_and_formatted_batting.csv\", df_batting_combined_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac78870",
   "metadata": {},
   "source": [
    "#### 3b. Combining and formatting bowling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "61dfe2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatBowlingCombined(df_bowling_combined):\n",
    "    # Will divide average, economy and Strike Rate by number of seasons to get the average of these metrics across all seasons\n",
    "    df_bowling_combined['Avg'] = round(df_bowling_combined['Avg'] / df_bowling_combined['Seasons'],2)\n",
    "    df_bowling_combined['SR'] = round(df_bowling_combined['SR'] / df_bowling_combined['Seasons'],2)\n",
    "    df_bowling_combined['Econ'] = round(df_bowling_combined['Econ'] / df_bowling_combined['Seasons'],2)\n",
    "    \n",
    "    return df_bowling_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e9d0255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_and_formatted_bowling.csv was written to successfully!\n"
     ]
    }
   ],
   "source": [
    "bowling_list = [df_clean_bowling_2016, df_clean_bowling_2017, df_clean_bowling_2018, df_clean_bowling_2019, df_clean_bowling_2020\n",
    "                , df_clean_bowling_2021, df_clean_bowling_2022]\n",
    "\n",
    "df_bowling_combined = combineDataFramesWithSeasonCount(bowling_list)\n",
    "df_bowling_combined_formatted = formatBowlingCombined(df_bowling_combined)\n",
    "write_csv_data(\"Outputs\\Combined\", \"combined_and_formatted_bowling.csv\", df_bowling_combined_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d0b68",
   "metadata": {},
   "source": [
    "### 4. Merging the dataframes\n",
    "Before performing analysis on the data, I think it is best to merge the batting and bowling dataframes into 1 each to better represent a player's performance over the course of the years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d5529",
   "metadata": {},
   "source": [
    "### 4a. Merging batting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c18dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge year 2016 and 2017\n",
    "batting_data_2016_2017_merged = batting_2016.merge(batting_2017, how='outer', on='Player', suffixes=('_2016', '_2017'))\n",
    "# Merge year 2018 and 2019\n",
    "batting_data_2018_2019_merged = batting_2018.merge(batting_2019, how='outer', on='Player', suffixes=('_2018', '_2019'))\n",
    "# Merge year 2016, 2017, 2018, and 2019\n",
    "batting_data_2016_2019_merged = batting_data_2016_2017_merged.merge(batting_data_2018_2019_merged, how='outer', on='Player')\n",
    "\n",
    "# Merge year 2020 and 2021\n",
    "batting_data_2020_2021_merged = batting_2020.merge(batting_2021, how='outer', on='Player', suffixes=('_2020', '_2021'))\n",
    "# Add suffix to 2022 before merging it\n",
    "batting_2022 = batting_2022.add_suffix('_2022')\n",
    "batting_2022 = batting_2022.rename(columns={\"Player_2022\": \"Player\"})\n",
    "# Merge year 2020, 2021, and 2022\n",
    "batting_data_2020_2022_merged = batting_data_2020_2021_merged.merge(batting_2022, how='outer', on='Player')\n",
    "\n",
    "# Merge all dataframes together essentially\n",
    "batting_data_merged = batting_data_2016_2019_merged.merge(batting_data_2020_2022_merged, how='outer', on='Player')\n",
    "# Calling function to write a csv file to our output folder\n",
    "write_csv_data(\"Outputs\", \"batting_data_merged.csv\", batting_data_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390ff092",
   "metadata": {},
   "source": [
    "### 4b. Merging bowling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge year 2016 and 2017\n",
    "bowling_data_2016_2017_merged = bowling_2016.merge(bowling_2017, how='outer', on='Player', suffixes=('_2016', '_2017'))\n",
    "# Merge year 2018 and 2019\n",
    "bowling_data_2018_2019_merged = bowling_2018.merge(bowling_2019, how='outer', on='Player', suffixes=('_2018', '_2019'))\n",
    "# Merge year 2016, 2017, 2018, and 2019\n",
    "bowling_data_2016_2019_merged = bowling_data_2016_2017_merged.merge(bowling_data_2018_2019_merged, how='outer', on='Player')\n",
    "\n",
    "# Merge year 2020 and 2021\n",
    "bowling_data_2020_2021_merged = bowling_2020.merge(bowling_2021, how='outer', on='Player', suffixes=('_2020', '_2021'))\n",
    "# Add suffix to 2022 before merging it\n",
    "bowling_2022 = bowling_2022.add_suffix('_2022')\n",
    "bowling_2022 = bowling_2022.rename(columns={\"Player_2022\": \"Player\"})\n",
    "# Merge year 2020, 2021, and 2022\n",
    "bowling_data_2020_2022_merged = bowling_data_2020_2021_merged.merge(bowling_2022, how='outer', on='Player')\n",
    "\n",
    "# Merge all dataframes together essentially\n",
    "bowling_data_merged = bowling_data_2016_2019_merged.merge(bowling_data_2020_2022_merged, how='outer', on='Player')\n",
    "# Calling function to write a csv file to our output folder\n",
    "write_csv_data(\"Outputs\", \"bowling_data_merged.csv\", bowling_data_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324ca2d",
   "metadata": {},
   "source": [
    "### 5. Dropping unneeded columns\n",
    "For the batting data, we do not need the POS field since merging the data will cause duplicates in this field. For bowling we do not need POS and Best Bowling Innings since the date value isn't relevant anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d360590",
   "metadata": {},
   "source": [
    "### 5a. Drop unneeded columns from merged datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f714550",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_merged.drop(['POS_2016', 'POS_2017', 'POS_2018', 'POS_2019', 'POS_2020', 'POS_2021', 'POS_2022'], axis=1, inplace=True)\n",
    "\n",
    "# Calling function to write a csv file to our output folder\n",
    "write_csv_data(\"Outputs\", \"batting_data_merged_dropped_unneeded_columns.csv\", batting_data_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4fced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowling_data_merged.drop(['POS_2016', 'POS_2017', 'POS_2018', 'POS_2019', 'POS_2020', 'POS_2021', 'POS_2022'], axis=1, inplace=True)\n",
    "bowling_data_merged.drop(['BBI_2016', 'BBI_2017', 'BBI_2018', 'BBI_2019', 'BBI_2020', 'BBI_2021', 'BBI_2022'], axis=1, inplace=True)\n",
    "\n",
    "# Calling function to write a csv file to our output folder\n",
    "write_csv_data(\"Outputs\", \"bowling_data_merged_dropped_unneeded_columns.csv\", bowling_data_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415247d5",
   "metadata": {},
   "source": [
    "### 6. Extracting more detailed information about each dataset\n",
    "We want to get a better feel for the data so we will use the describe method and info method again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea398f",
   "metadata": {},
   "source": [
    "### 6a. Describe method on the merged datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae901bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051572d3",
   "metadata": {},
   "source": [
    "Describe shows some basic statistics such as the average of all key statistics as well as the max for each field on the merged datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aea8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowling_data_merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b14cf79",
   "metadata": {},
   "source": [
    "### 6b. Describe method on the concatenated datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de1d24",
   "metadata": {},
   "source": [
    "We also want to analyze the concatenated datasets to ensure everything is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_concatenated.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowling_data_concatenated.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c0092",
   "metadata": {},
   "source": [
    "### 6c. Info function for merged datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde6b398",
   "metadata": {},
   "source": [
    "We can use info again but with show_counts enabled in order to see how many null values are present. Batting contains about 200 values per statistic column with a null value so we can impute that with a 0. Also need to convert all High Scores to a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_merged.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58419dbb",
   "metadata": {},
   "source": [
    "Bowling data does not have any issues with regards to data types but we need to fill the empty values with 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowling_data_merged.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6d001",
   "metadata": {},
   "source": [
    "### 6d. Info function for concatenated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_concatenated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b136ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowling_data_concatenated.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec4fad5",
   "metadata": {},
   "source": [
    "### 7. Fix data type issues\n",
    "Need to convert all the object fields to float64 in batting data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c12e1",
   "metadata": {},
   "source": [
    "The reason High Scores are objects and not float64 is because they contain an * field which indicates whether the person was not out or not. Since we have a field already tracking not outs, then we simply need to remove all occurrences of * in the high score before converting to a float."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf6462",
   "metadata": {},
   "source": [
    "### 7a. Fix issues in merged datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a570f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all occurrences of * in the high score\n",
    "batting_data_merged['HS_2016'] = batting_data_merged['HS_2016'].str.replace(\"*\", \"\")\n",
    "batting_data_merged['HS_2017'] = batting_data_merged['HS_2017'].str.replace(\"*\", \"\")\n",
    "batting_data_merged['HS_2018'] = batting_data_merged['HS_2018'].str.replace(\"*\", \"\")\n",
    "batting_data_merged['HS_2019'] = batting_data_merged['HS_2019'].str.replace(\"*\", \"\")\n",
    "batting_data_merged['HS_2020'] = batting_data_merged['HS_2020'].str.replace(\"*\", \"\")\n",
    "batting_data_merged['HS_2021'] = batting_data_merged['HS_2021'].str.replace(\"*\", \"\")\n",
    "batting_data_merged['HS_2022'] = batting_data_merged['HS_2022'].str.replace(\"*\", \"\")\n",
    "batting_data_merged['Avg_2022'] = batting_data_merged['Avg_2022'].str.replace(\"-\", \"0\")\n",
    "batting_data_merged['Avg_2022'] = batting_data_merged['Avg_2022'].str.strip(\"\")\n",
    "\n",
    "\n",
    "# Convert to a float\n",
    "batting_data_merged['HS_2016'] = batting_data_merged['HS_2016'].astype('float64')\n",
    "batting_data_merged['HS_2017'] = batting_data_merged['HS_2017'].astype('float64')\n",
    "batting_data_merged['HS_2018'] = batting_data_merged['HS_2018'].astype('float64')\n",
    "batting_data_merged['HS_2019'] = batting_data_merged['HS_2019'].astype('float64')\n",
    "batting_data_merged['HS_2020'] = batting_data_merged['HS_2020'].astype('float64')\n",
    "batting_data_merged['HS_2021'] = batting_data_merged['HS_2021'].astype('float64')\n",
    "batting_data_merged['HS_2022'] = batting_data_merged['HS_2022'].astype('float64')\n",
    "\n",
    "batting_data_merged['Avg_2022'] = batting_data_merged['Avg_2022'].astype('float64')\n",
    "\n",
    "# Calling function to write a csv file to our output folder\n",
    "write_csv_data(\"Outputs\", \"batting_data_merged_fixed_data_type_mismatches.csv\", batting_data_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13865a0f",
   "metadata": {},
   "source": [
    "Rerunning info method to verify if the data type conversions were successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb4a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_merged.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95d7db",
   "metadata": {},
   "source": [
    "Rerunning info method to verify everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ceb3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_concatenated.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb5d1a",
   "metadata": {},
   "source": [
    "### 8. Plotting Histograms for key attributes in merged batting data\n",
    "So instead of plotting histograms for all fields at once, I decided to plot similiar fields for all years together. So below I did runs for batting. Then I will do average, high scores, and matches for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462dc8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Batting runs\n",
    "batting_data_merged[['Runs_2016', 'Runs_2017', 'Runs_2018', 'Runs_2019', 'Runs_2020', 'Runs_2021', 'Runs_2022']].hist(bins=25, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e9a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batting matches\n",
    "batting_data_merged[['Mat_2016', 'Mat_2017', 'Mat_2018', 'Mat_2019', 'Mat_2020', 'Mat_2021', 'Mat_2022']].hist(bins=25, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2ccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batting average\n",
    "batting_data_merged[['Avg_2016', 'Avg_2017', 'Avg_2018', 'Avg_2019', 'Avg_2020', 'Avg_2021', 'Avg_2022']].hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batting high scores\n",
    "batting_data_merged[['HS_2016', 'HS_2017', 'HS_2018', 'HS_2019', 'HS_2020', 'HS_2021', 'HS_2022']].hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d60113",
   "metadata": {},
   "source": [
    "### 8a. Plotting histograms for key attributes in merged bowling data\n",
    "So instead of plotting histograms for all fields at once, I decided to plot similiar fields for all years together. So below I did wickets for bowling. Then I will do average, economy rate, and matches for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac28385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bowling wickets\n",
    "bowling_data_merged[['Wkts_2016', 'Wkts_2017', 'Wkts_2018', 'Wkts_2019', 'Wkts_2020', 'Wkts_2021', 'Wkts_2022']].hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bowling average\n",
    "bowling_data_merged[['Avg_2016', 'Avg_2017', 'Avg_2018', 'Avg_2019', 'Avg_2020', 'Avg_2021', 'Avg_2022']].hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bowling economy rates\n",
    "bowling_data_merged[['Econ_2016', 'Econ_2017', 'Econ_2018', 'Econ_2019', 'Econ_2020', 'Econ_2021', 'Econ_2022']].hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daec1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bowling matches\n",
    "bowling_data_merged[['Mat_2016', 'Mat_2017', 'Mat_2018', 'Mat_2019', 'Mat_2020', 'Mat_2021', 'Mat_2022']].hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6aafbc",
   "metadata": {},
   "source": [
    "### 9. Clean the data\n",
    "\n",
    "Need to inpute 0s for all nulls in both dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73bb76",
   "metadata": {},
   "source": [
    "### 9a. Clean the merged datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34235fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_merged.fillna(0, inplace=True)\n",
    "bowling_data_merged.fillna(0, inplace=True)\n",
    "\n",
    "# Calling function to write a csv file to our output folder\n",
    "write_csv_data(\"Outputs\", \"bowling_data_merged_filled_all_blanks.csv\", bowling_data_merged)\n",
    "write_csv_data(\"Outputs\", \"batting_data_merged_filled_all_blanks.csv\", batting_data_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc20a9",
   "metadata": {},
   "source": [
    "### 9b. Clean the concatenated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e3265",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_concatenated.fillna(0, inplace=True)\n",
    "bowling_data_concatenated.fillna(0, inplace=True)\n",
    "\n",
    "# Calling function to write a csv file to our output folder\n",
    "write_csv_data(\"Outputs\", \"bowling_data_concatenated_filled_all_blanks.csv\", bowling_data_concatenated)\n",
    "write_csv_data(\"Outputs\", \"batting_data_concatenated_filled_all_blanks.csv\", batting_data_concatenated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db264c1a",
   "metadata": {},
   "source": [
    "### 10. Need to create training and test sets\n",
    "By doing this, we do not get too familiar with a portion of the data which can affect us in choosing a proper model in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1579e",
   "metadata": {},
   "source": [
    "#### 10a. Doing the split on concatenated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0324a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "batting_data_concatenated_train_set, batting_data_concatenated_test_set = train_test_split(batting_data_concatenated, test_size=0.2, random_state=42)\n",
    "\n",
    "batting_data_concatenated_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7778443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowling_data_concatenated_train_set, bowling_data_concatenated_test_set = train_test_split(bowling_data_concatenated, test_size=0.2, random_state=42)\n",
    "\n",
    "bowling_data_concatenated_train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f8c20",
   "metadata": {},
   "source": [
    "#### 10b. Doing the split on merged datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9da870",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_merged_train_set, batting_data_merged_test_set = train_test_split(batting_data_merged, test_size=0.2, random_state=42)\n",
    "\n",
    "batting_data_merged_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowling_data_merged_train_set, bowling_data_merged_test_set = train_test_split(bowling_data_merged, test_size=0.2, random_state=42)\n",
    "\n",
    "bowling_data_merged_train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576599bd",
   "metadata": {},
   "source": [
    "### 11. Visualizing and gaining insights on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f211d7c4",
   "metadata": {},
   "source": [
    "First we will copy the training sets so we don't manipulate the original set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88139b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_concatenated_copy = batting_data_concatenated_train_set.copy()\n",
    "bowling_data_concatenated_copy = bowling_data_concatenated_train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309de3fb",
   "metadata": {},
   "source": [
    "Next, we want to create some visualizations such as scatter plots to better get a feel for the data. First we will plot runs against balls faced. It is evident that the more balls faced will lead to more runs naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c851818",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_concatenated_copy.plot(kind='scatter', x='Runs', y='BF', alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_concatenated_copy[\"Avg\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef877415",
   "metadata": {},
   "source": [
    "Next we will create a scatter plot of Runs to Average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2c2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_data_concatenated_copy.plot(kind='scatter', x='Avg', y='Runs', alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8786140",
   "metadata": {},
   "source": [
    "### 12. Running correlation functions to identify highly correlated features\n",
    "Here we want to run a correlation function to understand how correlated are the other attributes to each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a153fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_concatenated_corr_matrix = batting_data_concatenated_copy.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5533b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowling_concatenated_corr_matrix = bowling_data_concatenated_copy.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_concatenated_corr_matrix[\"Runs\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86282ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowling_concatenated_corr_matrix[\"Wkts\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc40452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
